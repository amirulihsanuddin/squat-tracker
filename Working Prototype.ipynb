{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1216b8-876b-4b1c-9269-bee4ab0e1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tkinter customtkinter\n",
    "!pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8a565b1-7cfa-4bb7-be8c-36be6c9c929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import customtkinter as ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b77851-701b-4b12-a681-f9865f5df8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eddcr\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#To set up the mediapipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "#Create array\n",
    "landmarks = ['class']\n",
    "for val in range(1, 33+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc4b2fe8-70e8-4c88-ab2f-b7877b8f6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .pkl file for the first set of data\n",
    "with open('model1.pkl', 'rb') as f:\n",
    "    model1 = pickle.load(f)\n",
    "\n",
    "# Load the .pkl file for the second set of data\n",
    "with open('model2.pkl', 'rb') as f:\n",
    "    model2 = pickle.load(f)\n",
    "\n",
    "def tracker(feed):\n",
    "    counter = 0\n",
    "    current_stage = ''\n",
    "    cap = cv2.VideoCapture(feed)\n",
    "    pause = False  # Flag to indicate whether the video is paused\n",
    "    # up_accuracy = []\n",
    "    # down_accuracy = []   \n",
    "    # upbad_accuracy = []\n",
    "    # downbad_accuracy = [] \n",
    "    # bend_accuracy = []   \n",
    "    # cavein_accuracy = []  \n",
    "    # caveout_accuracy = [] \n",
    "    # good_accuracy = []  \n",
    "\n",
    "    # initiate holistic model\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Make Detection\n",
    "            results = pose.process(image)\n",
    "\n",
    "            # Recolor image to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            landmark_color = (255, 255, 255)\n",
    "\n",
    "            try:\n",
    "                row = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()\n",
    "                X = pd.DataFrame([row], columns=landmarks[1:])\n",
    "                body_language_class1 = model1.predict(X)[0]\n",
    "                body_language_prob1 = model1.predict_proba(X)[0]\n",
    "                print(body_language_class1, body_language_prob1)\n",
    "\n",
    "                body_language_class2 = model2.predict(X)[0]\n",
    "                body_language_prob2 = model2.predict_proba(X)[0]\n",
    "                print(body_language_class2, body_language_prob2)\n",
    "                \n",
    "#                 if body_language_class1 == 'up':\n",
    "#                     up_accuracy.append(body_language_prob1[np.argmax(body_language_prob1)])\n",
    "#                 elif body_language_class1 == 'down':\n",
    "#                     down_accuracy.append(body_language_prob1[np.argmax(body_language_prob1)])\n",
    "#                 elif body_language_class1 == 'upbad':\n",
    "#                     upbad_accuracy.append(body_language_prob1[np.argmax(body_language_prob1)])\n",
    "#                 elif body_language_class1 == 'downbad':\n",
    "#                     downbad_accuracy.append(body_language_prob1[np.argmax(body_language_prob1)])\n",
    "\n",
    "#                 if body_language_class2 == 'bend':\n",
    "#                     bend_accuracy.append(body_language_prob2[np.argmax(body_language_prob2)])\n",
    "#                 elif body_language_class2 == 'cavein':\n",
    "#                     cavein_accuracy.append(body_language_prob2[np.argmax(body_language_prob2)])\n",
    "#                 elif body_language_class2 == 'caveout':\n",
    "#                     caveout_accuracy.append(body_language_prob2[np.argmax(body_language_prob2)])\n",
    "#                 elif body_language_class2 == 'good':\n",
    "#                     good_accuracy.append(body_language_prob2[np.argmax(body_language_prob2)])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                # to draw landmarks\n",
    "                if body_language_class1 == 'downbad':\n",
    "                    landmark_color = (0, 0, 255)  # Change color to red for 'downbad'\n",
    "                elif body_language_class1 == 'upbad':\n",
    "                    landmark_color = (0, 0, 255)  # Change color to green for 'upbad'\n",
    "                    \n",
    "                if body_language_class2 == 'bend':\n",
    "                    landmark_color = (0, 0, 255)  # Change color to yellow for 'bend'\n",
    "                elif body_language_class2 == 'cavein':\n",
    "                    landmark_color = (0, 0, 255)  # Change color to cyan for 'cavein'\n",
    "                elif body_language_class2 == 'caveout':\n",
    "                     landmark_color = (0, 0, 255)  # Change color to magenta for 'caveout'\n",
    "\n",
    "                        \n",
    "                        \n",
    "                # counter\n",
    "                if body_language_class1 == 'up' and body_language_prob1[body_language_prob1.argmax()] >= .7:\n",
    "                    current_stage = 'up'\n",
    "                elif current_stage == 'up' and body_language_class1 == 'down' and body_language_prob1[body_language_prob1.argmax()] >= .7:\n",
    "                    current_stage=\"down\"\n",
    "                    counter +=1\n",
    "                    print(current_stage)\n",
    "                    \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "#                 image = np.zeros((720, 1280, 3), dtype=np.uint8)\n",
    "\n",
    "#                 # Calculate position to center the image on the canvas\n",
    "#                 y_offset = (720 - image.shape[0]) // 2\n",
    "#                 x_offset = (1280 - image.shape[1]) // 2\n",
    "\n",
    "#                 # Overlay the image onto the canvas\n",
    "#                 image[y_offset:y_offset + image.shape[0], x_offset:x_offset + image.shape[1]] = image\n",
    "\n",
    "\n",
    "                # Render detections\n",
    "                drawing_spec = mp_drawing.DrawingSpec(color=landmark_color, circle_radius=5)\n",
    "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                          mp_drawing.DrawingSpec(color=(245, 117, 16), thickness=2, circle_radius=2),\n",
    "                                          connection_drawing_spec=drawing_spec\n",
    "                                         )\n",
    "                \n",
    "                # if feed == 1:\n",
    "                #     image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "                \n",
    "                #Get status box\n",
    "                cv2.rectangle (image, (0,0), (540, 60), (245, 117, 16), -1)\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                #display probability\n",
    "                cv2.putText(image, 'PROB'\n",
    "                            , (10,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, str(round(body_language_prob1[np.argmax(body_language_prob1)],2))\n",
    "                            , (15,40), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                #Display Up or Down\n",
    "                cv2.putText(image, 'CLASS'\n",
    "                            , (90,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, body_language_class1.split(' ')[0]\n",
    "                            , (95,40), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "                #display counter\n",
    "                cv2.putText(image, 'COUNT'\n",
    "                            , (220,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, str(counter)\n",
    "                            , (225,40), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "                #Display Class\n",
    "                cv2.putText(image, 'FORM'\n",
    "                            , (290,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, body_language_class2.split(' ')[0]\n",
    "                            , (295,40), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                \n",
    "\n",
    "                #display probability\n",
    "                cv2.putText(image, 'FORM PROB'\n",
    "                            , (420,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, str(round(body_language_prob2[np.argmax(body_language_prob2)],2))\n",
    "                            , (425,40), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255), 2, cv2.LINE_AA)\n",
    "                \n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Error\")\n",
    "                pass\n",
    "            \n",
    "            # up_accuracy.append(0)\n",
    "            # down_accuracy.append(0)\n",
    "            # upbad_accuracy.append(0)\n",
    "            # downbad_accuracy.append(0)\n",
    "            # bend_accuracy.append(0)\n",
    "            # cavein_accuracy.append(0)\n",
    "            # caveout_accuracy.append(0)\n",
    "            # good_accuracy.append(0)\n",
    "\n",
    "            k = cv2.waitKey(1)\n",
    "            if k == 27:  # press Esc key to exit\n",
    "                break\n",
    "\n",
    "            if not pause:\n",
    "                #cv2.imshow('Mediapipe Feed', image)\n",
    "                \n",
    "                if feed == 1:\n",
    "\n",
    "                    #image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "                    display_image = cv2.resize(image, (960, 720))\n",
    "                    cv2.imshow('Mediapipe Feed', display_image)\n",
    "                else:\n",
    "                    display_image = cv2.resize(image, (1280, 720))\n",
    "                    cv2.imshow('Mediapipe Feed', display_image)\n",
    "\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        if cv2.waitKey(0) & 0xFF == ord('p'):\n",
    "        # If 'p' is pressed after a video, pause before proceeding to the next video\n",
    "            pause = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e9219-13f5-40d8-a53e-bebf61d9e153",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tkinter import filedialog\n",
    "\n",
    "ck.set_appearance_mode(\"Dark\")\n",
    "ck.set_default_color_theme(\"blue\")\n",
    "\n",
    "app = ck.CTk()\n",
    "app.geometry(\"1280x720\")\n",
    "app.title(\"Motion Tracker\")\n",
    "\n",
    "    \n",
    "def open_video():\n",
    "    feed = filedialog.askopenfilename(filetypes=[(\"Video files\", \"*.mp4;*.avi;*.mkv\")])\n",
    "    if feed:\n",
    "        tracker(feed)\n",
    "    \n",
    "def open_webcam():\n",
    "    tracker(0)  # 0 represents the default camera (webcam)\n",
    "\n",
    "title = ck.CTkLabel(app, text=\"Choose what to do\", font=('Arial',40))\n",
    "title.place(relx=0.5, rely=0.33, anchor='center')\n",
    "\n",
    "button1 = ck.CTkButton(app, text=\"Video\", command=open_video, font=('Arial', 40))\n",
    "button1.place(relx=0.25, rely=0.67, anchor='center')\n",
    "\n",
    "button2 = ck.CTkButton(app, text=\"Live\", command=open_webcam, font=('Arial', 40))\n",
    "button2.place(relx=0.75, rely=0.67, anchor='center')\n",
    "\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd139c9a-b668-4add-92d8-d1ec5ecda2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
